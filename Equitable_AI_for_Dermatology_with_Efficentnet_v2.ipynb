{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wl_PYLfYq6Vh"
      },
      "outputs": [],
      "source": [
        "!pip install -U efficientnet\n",
        "!pip install tensorflow\n",
        "# !pip install efficientnet_pytorch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata, files\n",
        "import efficientnet.keras as efn\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import WeightedRandomSampler\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision"
      ],
      "metadata": {
        "id": "nKTzwT65vxmh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the Kaggle Data"
      ],
      "metadata": {
        "id": "8UgpbgFDwk5V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2FW9qhXpQ8hp"
      },
      "outputs": [],
      "source": [
        "os.environ[\"KAGGLE_KEY\"] = userdata.get('KAGGLE_KEY')\n",
        "os.environ[\"KAGGLE_USERNAME\"] = userdata.get('KAGGLE_USERNAME')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tmuXcJKHm-BI"
      },
      "outputs": [],
      "source": [
        "! pip install -q kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QBCMvaWhnBPN"
      },
      "outputs": [],
      "source": [
        "! kaggle datasets list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SzOyWAc0nDnR"
      },
      "outputs": [],
      "source": [
        "! kaggle competitions download -c bttai-ajl-2025"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OzaSyA07nJIf"
      },
      "outputs": [],
      "source": [
        "! mkdir kaggle_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7JObDuUnnKn0"
      },
      "outputs": [],
      "source": [
        "! unzip bttai-ajl-2025.zip -d kaggle_data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preparation"
      ],
      "metadata": {
        "id": "5rTILDG_w2Ly"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XSQ8Jm3Uncfa"
      },
      "outputs": [],
      "source": [
        "# Global Variables\n",
        "\n",
        "train_dir = '/content/kaggle_data/train/train'\n",
        "test_dir = '/content/kaggle_data/test/test'\n",
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 256\n",
        "# 16, 32, 64, 128, 256, 512, 1024+ for potential batch size\n",
        "# Start small, increase gradually, monitor stability\n",
        "epochs = 25 # tested with 20 for EfficientNet7 and it was 62% which is slightly lower than previous models\n",
        "# For epochs, 10–50 for small datasets\n",
        "# Start with a larger number, use early stopping to avoid overfitting\n",
        "VALIDATION_SPLIT = 0.2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define transformations\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Load training data\n",
        "train_dataset = datasets.ImageFolder(root=train_dir, transform=train_transform)\n",
        "\n",
        "# Create a DataLoader\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)"
      ],
      "metadata": {
        "id": "m_5OTywaxVoc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute class weights\n",
        "class_counts = np.array([len(os.listdir(os.path.join(train_dir, cls))) for cls in train_dataset.classes])\n",
        "class_weights = 1. / class_counts\n",
        "sample_weights = class_weights[train_dataset.targets]\n",
        "\n",
        "# Create a weighted sampler\n",
        "sampler = WeightedRandomSampler(weights=sample_weights, num_samples=len(train_dataset), replacement=True)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, sampler=sampler)\n",
        "\n",
        "import torch, gc\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "\n"
      ],
      "metadata": {
        "id": "kuXKl8DQy9o8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "438a057d-b6b1-423b-b7cd-5b72fb057dea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5897"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Training"
      ],
      "metadata": {
        "id": "glhn8sBq0ZBC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, gc\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "\n",
        "# Restart runtime first to free all GPU memory!\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Clear any cached memory (just in case)\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "\n",
        "# Load pretrained EfficientNet_V2_M (≈10 GB VRAM)\n",
        "weights = torchvision.models.EfficientNet_V2_M_Weights.IMAGENET1K_V1\n",
        "model = torchvision.models.efficientnet_v2_m(weights=weights)\n",
        "\n",
        "# Replace classification head\n",
        "in_features = model.classifier[1].in_features\n",
        "model.classifier[1] = nn.Linear(in_features, len(train_dataset.classes))\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "# Loss + optimizer\n",
        "criterion = nn.CrossEntropyLoss(weight=torch.tensor(class_weights, dtype=torch.float32, device=device))\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "    print(f'Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(train_loader):.4f}')\n",
        "\n",
        "# Save checkpoint\n",
        "torch.save({\n",
        "    'model_state_dict': model.state_dict(),\n",
        "    'class_to_idx': train_dataset.class_to_idx\n",
        "}, 'efficientnet_v2_m_finetuned.pth')\n"
      ],
      "metadata": {
        "id": "tjnft1_3z10l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64f56f8a-f57f-4e3e-e315-f3dd0891589e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/25], Loss: 2.2617\n",
            "Epoch [2/25], Loss: 1.1013\n",
            "Epoch [3/25], Loss: 0.5926\n",
            "Epoch [4/25], Loss: 0.4054\n",
            "Epoch [5/25], Loss: 0.2495\n",
            "Epoch [6/25], Loss: 0.1835\n",
            "Epoch [7/25], Loss: 0.1376\n",
            "Epoch [8/25], Loss: 0.1117\n",
            "Epoch [9/25], Loss: 0.0931\n",
            "Epoch [10/25], Loss: 0.0729\n",
            "Epoch [11/25], Loss: 0.0729\n",
            "Epoch [12/25], Loss: 0.0744\n",
            "Epoch [13/25], Loss: 0.0543\n",
            "Epoch [14/25], Loss: 0.0519\n",
            "Epoch [15/25], Loss: 0.0462\n",
            "Epoch [16/25], Loss: 0.0406\n",
            "Epoch [17/25], Loss: 0.0348\n",
            "Epoch [18/25], Loss: 0.0453\n",
            "Epoch [19/25], Loss: 0.0327\n",
            "Epoch [20/25], Loss: 0.0260\n",
            "Epoch [21/25], Loss: 0.0332\n",
            "Epoch [22/25], Loss: 0.0281\n",
            "Epoch [23/25], Loss: 0.0303\n",
            "Epoch [24/25], Loss: 0.0532\n",
            "Epoch [25/25], Loss: 0.0447\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        preds = outputs.argmax(dim=1)\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "train_accuracy = correct / total\n",
        "print(f\"Training Accuracy: {train_accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hFnT5escxOPi",
        "outputId": "c34a3bb1-6706-45d5-ef80-6bdeb789852f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy: 99.27%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "owUkFtm10fXk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = torch.load('vit_l_16_finetuned.pth', map_location='cpu')\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "model = model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# Prepare test images list\n",
        "test_images = [os.path.join(test_dir, img) for img in os.listdir(test_dir)]\n",
        "\n",
        "predictions = []\n",
        "hashes = []\n",
        "\n",
        "for img_path in test_images:\n",
        "    # Filename (without extension) as hash\n",
        "    hashes.append(os.path.splitext(os.path.basename(img_path))[0])\n",
        "\n",
        "    # Load + transform\n",
        "    img = Image.open(img_path).convert('RGB')\n",
        "    img = train_transform(img).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model(img)\n",
        "        pred_idx = output.argmax(dim=1).item()\n",
        "        predictions.append(train_dataset.classes[pred_idx])\n",
        "\n",
        "# Write to CSV\n",
        "df = pd.DataFrame({'md5hash': hashes, 'label': predictions})\n",
        "df.to_csv('vit_predictions.csv', index=False)"
      ],
      "metadata": {
        "id": "NqaOhmvn0uhg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the files locally\n",
        "from google.colab import files\n",
        "# files.download('vit_l_16_finetuned.pth') # change name of model\n",
        "files.download('efficientnet_v2_m_finetuned.pth')"
      ],
      "metadata": {
        "id": "_3YDmKHe0Ecp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f9f5f0b2-9277-491f-a52a-108e9c64027b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_5fc8d7f6-d62f-401b-9a3e-1392818e9a6d\", \"efficientnet_v2_m_finetuned.pth\", 213139770)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dBTp6zlgUn95"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}